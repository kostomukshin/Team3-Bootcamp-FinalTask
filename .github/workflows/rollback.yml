name: Disaster Rollback (stable <- previous, refresh)

on:
  workflow_dispatch: {}

env:
  AWS_REGION: eu-west-1
  AWS_DEFAULT_REGION: eu-west-1
  ECR_REPO_NAME: custom-wordpress
  ASG_NAME: wp-asg

jobs:
  rollback:
    runs-on: [self-hosted, Linux, X64]

    steps:
      - name: Verify AWS identity
        run: aws sts get-caller-identity

      - name: Validate 'previous' tag exists
        run: |
          set -euo pipefail
          PREV_DIGEST=$(aws ecr describe-images \
            --repository-name "${ECR_REPO_NAME}" \
            --image-ids imageTag=previous \
            --region "${AWS_REGION}" \
            --query 'imageDetails[0].imageDigest' \
            --output text 2>/dev/null || true)

          if [ -z "$PREV_DIGEST" ] || [ "$PREV_DIGEST" = "None" ]; then
            echo "ERROR: 'previous' tag not found in ECR. Cannot rollback."
            exit 1
          fi

          echo "previous digest: $PREV_DIGEST"

      - name: Set stable <- previous
        run: |
          set -euo pipefail

          MANIFEST=$(aws ecr batch-get-image \
            --repository-name "${ECR_REPO_NAME}" \
            --image-ids imageTag="previous" \
            --region "${AWS_REGION}" \
            --query 'images[0].imageManifest' \
            --output text)

          if [ -z "$MANIFEST" ] || [ "$MANIFEST" = "None" ]; then
            echo "ERROR: Could not read manifest for 'previous'."
            exit 1
          fi

          aws ecr put-image \
            --repository-name "${ECR_REPO_NAME}" \
            --image-tag "stable" \
            --image-manifest "$MANIFEST" \
            --region "${AWS_REGION}"

          echo "Rollback applied: stable <- previous"

      - name: Start ASG Instance Refresh
        if: ${{ success() }}
        id: start_refresh
        run: |
          set -euxo pipefail
          REFRESH_ID=$(aws autoscaling start-instance-refresh \
            --auto-scaling-group-name "${ASG_NAME}" \
            --preferences MinHealthyPercentage=100,MaxHealthyPercentage=200,InstanceWarmup=120 \
            --region "${AWS_REGION}" \
            --query "InstanceRefreshId" --output text)
          echo "refresh_id=${REFRESH_ID}" >> $GITHUB_OUTPUT
          echo "Started Instance Refresh: ${REFRESH_ID}"

      - name: Wait for Instance Refresh to complete
        if: ${{ success() }}
        run: |
          set -euo pipefail
          REFRESH_ID="${{ steps.start_refresh.outputs.refresh_id }}"
          echo "Waiting for Instance Refresh: ${REFRESH_ID}"

          for i in $(seq 1 120); do
            STATUS=$(aws autoscaling describe-instance-refreshes \
              --auto-scaling-group-name "${ASG_NAME}" \
              --instance-refresh-ids "${REFRESH_ID}" \
              --region "${AWS_REGION}" \
              --query "InstanceRefreshes[0].Status" --output text)

            REASON=$(aws autoscaling describe-instance-refreshes \
              --auto-scaling-group-name "${ASG_NAME}" \
              --instance-refresh-ids "${REFRESH_ID}" \
              --region "${AWS_REGION}" \
              --query "InstanceRefreshes[0].StatusReason" --output text)

            echo "[$i/120] Status=${STATUS} Reason=${REASON}"

            if [ "${STATUS}" = "Successful" ]; then
              echo "Rollback refresh completed successfully."
              exit 0
            fi

            if [ "${STATUS}" = "Failed" ] || [ "${STATUS}" = "Cancelled" ]; then
              echo "Rollback refresh did not complete: ${STATUS} (${REASON})"
              exit 1
            fi

            sleep 15
          done

          echo "Timeout waiting for rollback refresh."
          exit 1
